{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Student  Details\n",
        "\n",
        "Student Name - Aryank Gupta\n",
        "\n",
        "Student ID - 24101613"
      ],
      "metadata": {
        "id": "IhYtI4LTgimQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1\n",
        "\n",
        "a). Modify your Multinomial Naïve Bayes (MNB) classifier from Etivity5, Task2 to train and test a sentiment classifier."
      ],
      "metadata": {
        "id": "n6naMVJ8hs5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def multinomialNaiveBayesClassifier(trainingSet, testSet):\n",
        "\n",
        "    # On Preprocessing Separate positive and negative data\n",
        "    positive_words = []\n",
        "    negative_words = []\n",
        "    for text, label in trainingSet:\n",
        "        words = text.lower().split()\n",
        "        if label == '+':\n",
        "            positive_words.extend(words)\n",
        "        else:\n",
        "            negative_words.extend(words)\n",
        "\n",
        "    # To calculate the word frequencies\n",
        "    pos_BOW = {word: positive_words.count(word) for word in set(positive_words)}\n",
        "    neg_BOW = {word: negative_words.count(word) for word in set(negative_words)}\n",
        "\n",
        "    pos_count = sum(pos_BOW.values())\n",
        "    neg_count = sum(neg_BOW.values())\n",
        "\n",
        "    # Vocabulary size\n",
        "    vocabulary = set(positive_words + negative_words)\n",
        "    vocab_size = len(vocabulary)\n",
        "\n",
        "    prob_pos = pos_count / (pos_count + neg_count)\n",
        "    prob_neg = neg_count / (pos_count + neg_count)\n",
        "\n",
        "    print(f\"posCount={pos_count}\")\n",
        "    print(f\"negCount={neg_count}\")\n",
        "    print(f\"probPos={prob_pos:.4f}\")\n",
        "    print(f\"probNeg={prob_neg:.4f}\")\n",
        "    print(f\"pos_BOW={pos_BOW}\")\n",
        "    print(f\"neg_BOW={neg_BOW}\")\n",
        "    print(f\"Vocabulary={vocabulary}\")\n",
        "    print(f\"|V|={vocab_size}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    for text, _ in testSet:\n",
        "        words = text.lower().split()\n",
        "        doc_prob_pos = math.log(prob_pos)\n",
        "        doc_prob_neg = math.log(prob_neg)\n",
        "\n",
        "        print(f\"Test document=('{text}', '?')\")\n",
        "        for word in words:\n",
        "            word_conditional_prob_pos = (pos_BOW.get(word, 0) + 1) / (pos_count + vocab_size)\n",
        "            word_conditional_prob_neg = (neg_BOW.get(word, 0) + 1) / (neg_count + vocab_size)\n",
        "\n",
        "            doc_prob_pos += math.log(word_conditional_prob_pos)\n",
        "            doc_prob_neg += math.log(word_conditional_prob_neg)\n",
        "\n",
        "            print(f'word= \"{word}\"  wordConditionalProbPos={word_conditional_prob_pos:.4f}  wordConditionalProbNeg={word_conditional_prob_neg:.4f}')\n",
        "\n",
        "        inferred_class = '+' if doc_prob_pos > doc_prob_neg else '-'\n",
        "        print(f\"docProbPos={doc_prob_pos:.4f}\")\n",
        "        print(f\"docProbNeg={doc_prob_neg:.4f}\")\n",
        "        print(f\"Inferred class={inferred_class}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "\n",
        "trainingSet = [\n",
        "    ('Boxing scene was a disappointment', '-'),\n",
        "    ('No plot twists or great scenes', '-'),\n",
        "    ('Great satire and great plot twists', '+'),\n",
        "    ('Great scenes a great film', '+')\n",
        "]\n",
        "\n",
        "testSet = [('Great disappointment indeed', '?')]\n",
        "\n",
        "multinomialNaiveBayesClassifier(trainingSet, testSet)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVUfqwr0hssg",
        "outputId": "6880a1b1-3a33-4763-9b6d-bd1be35f3e3f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "posCount=11\n",
            "negCount=11\n",
            "probPos=0.5000\n",
            "probNeg=0.5000\n",
            "pos_BOW={'twists': 1, 'film': 1, 'plot': 1, 'and': 1, 'great': 4, 'satire': 1, 'scenes': 1, 'a': 1}\n",
            "neg_BOW={'twists': 1, 'or': 1, 'no': 1, 'plot': 1, 'boxing': 1, 'great': 1, 'scenes': 1, 'a': 1, 'was': 1, 'scene': 1, 'disappointment': 1}\n",
            "Vocabulary={'twists', 'film', 'or', 'plot', 'no', 'and', 'great', 'satire', 'scenes', 'boxing', 'a', 'was', 'scene', 'disappointment'}\n",
            "|V|=14\n",
            "----------------------------------------\n",
            "Test document=('Great disappointment indeed', '?')\n",
            "word= \"great\"  wordConditionalProbPos=0.2000  wordConditionalProbNeg=0.0800\n",
            "word= \"disappointment\"  wordConditionalProbPos=0.0400  wordConditionalProbNeg=0.0800\n",
            "word= \"indeed\"  wordConditionalProbPos=0.0400  wordConditionalProbNeg=0.0400\n",
            "docProbPos=-8.7403\n",
            "docProbNeg=-8.9635\n",
            "Inferred class=+\n",
            "----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "b). Copy your solution for (a) into a new code cell.  Modify your code to optimise it for the task of sentiment analysis, i.e., change your classification algorithm from MNB to BMNB (Binary Multinomial Naïve Bayes)."
      ],
      "metadata": {
        "id": "KXIkU-dah8GU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def binaryMultinomialNaiveBayesClassifier(trainingSet, testSet):\n",
        "    wordsPos = set()\n",
        "    wordsNeg = set()\n",
        "    countPos = 0\n",
        "    countNeg = 0\n",
        "    pos_BOW = {}\n",
        "    neg_BOW = {}\n",
        "\n",
        "    for doc, label in trainingSet:\n",
        "        unique_words = set(doc.lower().split())  # Convert to lowercase and take unique words\n",
        "        if label == '+':\n",
        "            wordsPos.update(unique_words)\n",
        "            countPos += 1\n",
        "            for word in unique_words:\n",
        "                pos_BOW[word] = pos_BOW.get(word, 0) + 1\n",
        "        elif label == '-':\n",
        "            wordsNeg.update(unique_words)\n",
        "            countNeg += 1\n",
        "            for word in unique_words:\n",
        "                neg_BOW[word] = neg_BOW.get(word, 0) + 1\n",
        "\n",
        "    probPos = countPos / (countPos + countNeg)\n",
        "    probNeg = countNeg / (countPos + countNeg)\n",
        "\n",
        "    V = wordsPos | wordsNeg\n",
        "    V_size = len(V)\n",
        "\n",
        "    print(f'Probability of Positive = {probPos}')\n",
        "    print(f'Probability of Negative = {probNeg}')\n",
        "    print(f'Positive BOW = {pos_BOW}, len = {len(pos_BOW)}')\n",
        "    print(f'Negative BOW = {neg_BOW}, len = {len(neg_BOW)}')\n",
        "    print(f'Vocabulary (V) = {V}')\n",
        "    print(f'|V| = {V_size}')\n",
        "    print('-' * 30)\n",
        "\n",
        "    for test in testSet:\n",
        "        doc_text = test[0]\n",
        "        print(f\"Test Document = '{doc_text}'\")\n",
        "\n",
        "        docProbPos = math.log(probPos)\n",
        "        docProbNeg = math.log(probNeg)\n",
        "\n",
        "        test_words = set(doc_text.lower().split())\n",
        "\n",
        "        for word in test_words:\n",
        "            print(f\"Word = '{word}'\")\n",
        "            if word not in V:\n",
        "                print(f\"  Word '{word}' not in vocabulary, skipping.\")\n",
        "                continue\n",
        "\n",
        "            word_probPos = (pos_BOW.get(word, 0) + 1) / (countPos + V_size)\n",
        "            word_probNeg = (neg_BOW.get(word, 0) + 1) / (countNeg + V_size)\n",
        "\n",
        "            docProbPos += math.log(word_probPos)\n",
        "            docProbNeg += math.log(word_probNeg)\n",
        "\n",
        "            print(f\"  wordConditionalProbPos = {word_probPos:.6f}, wordConditionalProbNeg = {word_probNeg:.6f}\")\n",
        "\n",
        "        finalProbPos = math.exp(docProbPos)\n",
        "        finalProbNeg = math.exp(docProbNeg)\n",
        "        print(f'docProbPos = {finalProbPos:.4e} , docProbNeg = {finalProbNeg:.4e}')\n",
        "        if docProbPos > docProbNeg:\n",
        "            print(f\"Inferred Sentiment: Positive (+)\")\n",
        "        else:\n",
        "            print(f\"Inferred Sentiment: Negative (-)\")\n",
        "        print('-' * 30)\n",
        "\n",
        "trainingSet = [\n",
        "    ('Boxing scene was a disappointment', '-'),\n",
        "    ('No plot twists or great scenes', '-'),\n",
        "    ('Great satire and great plot twists', '+'),\n",
        "    ('Great scenes a great film', '+')\n",
        "]\n",
        "testSet = [\n",
        "    ('Great disappointment indeed', '?')\n",
        "]\n",
        "\n",
        "binaryMultinomialNaiveBayesClassifier(trainingSet, testSet)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pqs3TyhDh9xG",
        "outputId": "6d6a7b9b-3181-491f-d9e1-2987cd144ae2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of Positive = 0.5\n",
            "Probability of Negative = 0.5\n",
            "Positive BOW = {'twists': 1, 'plot': 1, 'and': 1, 'great': 2, 'satire': 1, 'a': 1, 'scenes': 1, 'film': 1}, len = 8\n",
            "Negative BOW = {'boxing': 1, 'a': 1, 'was': 1, 'scene': 1, 'disappointment': 1, 'twists': 1, 'or': 1, 'no': 1, 'plot': 1, 'great': 1, 'scenes': 1}, len = 11\n",
            "Vocabulary (V) = {'film', 'plot', 'satire', 'great', 'a', 'disappointment', 'twists', 'or', 'no', 'and', 'boxing', 'scenes', 'was', 'scene'}\n",
            "|V| = 14\n",
            "------------------------------\n",
            "Test Document = 'Great disappointment indeed'\n",
            "Word = 'indeed'\n",
            "  Word 'indeed' not in vocabulary, skipping.\n",
            "Word = 'great'\n",
            "  wordConditionalProbPos = 0.187500, wordConditionalProbNeg = 0.125000\n",
            "Word = 'disappointment'\n",
            "  wordConditionalProbPos = 0.062500, wordConditionalProbNeg = 0.125000\n",
            "docProbPos = 5.8594e-03 , docProbNeg = 7.8125e-03\n",
            "Inferred Sentiment: Negative (-)\n",
            "------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 2"
      ],
      "metadata": {
        "id": "6V6nQVD2ipiv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write a Sentiment Analysis function that takes a string as input and identifies its sentiment using the TextBlob library."
      ],
      "metadata": {
        "id": "BjoPT_C-n1F-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from textblob import TextBlob\n",
        "\n",
        "def sentimentAnalyzer(string):\n",
        "    # Analyze the sentiment using TextBlob\n",
        "    analysis = TextBlob(string)\n",
        "    polarity = analysis.sentiment.polarity\n",
        "    subjectivity = analysis.sentiment.subjectivity\n",
        "\n",
        "    # Determine sentiment label\n",
        "    if polarity > 0:\n",
        "        sentiment_label = \"Positive sentiment 😊\"\n",
        "    elif polarity < 0:\n",
        "        sentiment_label = \"Negative sentiment 😞\"\n",
        "    else:\n",
        "        sentiment_label = \"Neutral sentiment 😐\"\n",
        "\n",
        "    # Print the output in the desired format\n",
        "    print(f\"String= {string}\\n\")\n",
        "    print(f\"Sentiment(polarity={polarity}, subjectivity={subjectivity})\")\n",
        "    print(sentiment_label)\n",
        "    print(f\"Subjectivity: {subjectivity}\")\n",
        "    print(\"-\" * 33)\n",
        "\n",
        "# Test strings\n",
        "test_strings = [\n",
        "    \"NLP is cool\",\n",
        "    \"NLP is cool and useful\",\n",
        "    \"NLP is hard\",\n",
        "    \"NLP is hard and useless\",\n",
        "    \"NLP stands for Natural Language Processing\"\n",
        "]\n",
        "\n",
        "# Run the function for each test string\n",
        "for sentence in test_strings:\n",
        "    sentimentAnalyzer(sentence)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZzFYhqoipM0",
        "outputId": "6cd32c8b-3827-4a7b-a961-8e550465884c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "String= NLP is cool\n",
            "\n",
            "Sentiment(polarity=0.35, subjectivity=0.65)\n",
            "Positive sentiment 😊\n",
            "Subjectivity: 0.65\n",
            "---------------------------------\n",
            "String= NLP is cool and useful\n",
            "\n",
            "Sentiment(polarity=0.32499999999999996, subjectivity=0.325)\n",
            "Positive sentiment 😊\n",
            "Subjectivity: 0.325\n",
            "---------------------------------\n",
            "String= NLP is hard\n",
            "\n",
            "Sentiment(polarity=-0.2916666666666667, subjectivity=0.5416666666666666)\n",
            "Negative sentiment 😞\n",
            "Subjectivity: 0.5416666666666666\n",
            "---------------------------------\n",
            "String= NLP is hard and useless\n",
            "\n",
            "Sentiment(polarity=-0.39583333333333337, subjectivity=0.37083333333333335)\n",
            "Negative sentiment 😞\n",
            "Subjectivity: 0.37083333333333335\n",
            "---------------------------------\n",
            "String= NLP stands for Natural Language Processing\n",
            "\n",
            "Sentiment(polarity=0.1, subjectivity=0.4)\n",
            "Positive sentiment 😊\n",
            "Subjectivity: 0.4\n",
            "---------------------------------\n"
          ]
        }
      ]
    }
  ]
}